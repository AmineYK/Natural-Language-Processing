{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence Processing with HMMs and CRFs\n",
    "\n",
    "**The goal of this practical is to study sequence models in NLP.**\n",
    "\n",
    "We will work on Part-Of-Speech (POS) and optionally on chunking (gathering different groups in sentences). The datasets are from [CONLL 2000](https://www.clips.uantwerpen.be/conll2000/chunking/): \n",
    "- **Small corpus:** chtrain/chtest to understand the tools and models \n",
    "- **Larger corpus:** train/test to collect reliable experimental results\n",
    "\n",
    "\n",
    "# 1) HMMS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading POS/Chunking data\n",
    "def load(filename):\n",
    "    listeDoc = list()\n",
    "    with open(filename, \"r\") as f:\n",
    "        doc = list()\n",
    "        for ligne in f:\n",
    "            if len(ligne) < 2: # fin de doc\n",
    "                listeDoc.append(doc)\n",
    "                doc = list()\n",
    "                continue\n",
    "            mots = ligne.replace(\"\\n\",\"\").split(\" \")\n",
    "            doc.append((mots[0],mots[1])) # Change mots[1] -> mots[2] for chuncking\n",
    "    return listeDoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "823  docs read\n",
      "77  docs (T) read\n"
     ]
    }
   ],
   "source": [
    "# =============== loding ============\n",
    "# small corpus => ideal for first tests\n",
    "filename = \"datasets/chtrain.txt\" \n",
    "filenameT = \"datasets/chtest.txt\" \n",
    "\n",
    "# Larger corpus => To valide perf.\n",
    "# filename = \"ressources/conll2000/train.txt\" \n",
    "# filenameT = \"ressources/conll2000/test.txt\" \n",
    "\n",
    "alldocs = load(filename)\n",
    "alldocsT = load(filenameT)\n",
    "\n",
    "print(len(alldocs),\" docs read\")\n",
    "print(len(alldocsT),\" docs (T) read\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Rockwell', 'NNP'), ('International', 'NNP'), ('Corp.', 'NNP'), (\"'s\", 'POS'), ('Tulsa', 'NNP'), ('unit', 'NN'), ('said', 'VBD'), ('it', 'PRP'), ('signed', 'VBD'), ('a', 'DT'), ('tentative', 'JJ'), ('agreement', 'NN'), ('extending', 'VBG'), ('its', 'PRP$'), ('contract', 'NN'), ('with', 'IN'), ('Boeing', 'NNP'), ('Co.', 'NNP'), ('to', 'TO'), ('provide', 'VB'), ('structural', 'JJ'), ('parts', 'NNS'), ('for', 'IN'), ('Boeing', 'NNP'), (\"'s\", 'POS'), ('747', 'CD'), ('jetliners', 'NNS'), ('.', '.')]\n",
      "[('Confidence', 'NN'), ('in', 'IN'), ('the', 'DT'), ('pound', 'NN'), ('is', 'VBZ'), ('widely', 'RB'), ('expected', 'VBN'), ('to', 'TO'), ('take', 'VB'), ('another', 'DT'), ('sharp', 'JJ'), ('dive', 'NN'), ('if', 'IN'), ('trade', 'NN'), ('figures', 'NNS'), ('for', 'IN'), ('September', 'NNP'), (',', ','), ('due', 'JJ'), ('for', 'IN'), ('release', 'NN'), ('tomorrow', 'NN'), (',', ','), ('fail', 'VB'), ('to', 'TO'), ('show', 'VB'), ('a', 'DT'), ('substantial', 'JJ'), ('improvement', 'NN'), ('from', 'IN'), ('July', 'NNP'), ('and', 'CC'), ('August', 'NNP'), (\"'s\", 'POS'), ('near-record', 'JJ'), ('deficits', 'NNS'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "print(alldocs[0])\n",
    "print(alldocsT[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a baseline POS model (without sequence)\n",
    "\n",
    "We will build a simple dictionary ```word => PoS label``` without taking into account any sequence information. We will compare the sequence models to this baseline.\n",
    "\n",
    "The dataset is a list a tuples with ```(word, POS)```. **Build a simple dictionary mapping each word to its PoS tag in the train set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary building \n",
    "def get_dict(alldocs):\n",
    "    dico = dict()\n",
    "    for doc in alldocs:\n",
    "        for word,pos in doc:\n",
    "            dico[word] = pos\n",
    "    return dico\n",
    "dico_baseline = get_dict(alldocs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Note: on the test set, there are unknown words...**. We will use the following simple strategy: \n",
    "```\n",
    "# remplace\n",
    "dico[cle] # crashing with an unknown key \n",
    "# by \n",
    "dico.get(cle, DefaultValue)\n",
    "```\n",
    "From a linguistic point of view, we can choose the default value as the majority PoS class, producing a stronger baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1896, 1527)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate test performances\n",
    "def test_eval(alldocs,alldocsT,default):\n",
    "    dico_baseline = get_dict(alldocs)\n",
    "    nb_word_corr = 0\n",
    "    nb_word = 0\n",
    "    for doc in alldocsT:\n",
    "        for word,pos in doc:\n",
    "            nb_word += 1\n",
    "            if dico_baseline.get(word,default) == pos:\n",
    "                nb_word_corr += 1\n",
    "    return nb_word,nb_word_corr\n",
    "test_eval(alldocs,alldocsT,'NN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check: 1433 good predictions in test over 1896\n",
    "\n",
    "(1527 with 'NN' as default PoS value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HMMs\n",
    "\n",
    "Here is a code for training HMM parameters and running decoding using the Viterbi algorithm. You should apply it to our PoS task. **N.B.: you should undersand the ```eps``` parmaters**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allx: list of observation sequences \n",
    "# allq: list os state sequences \n",
    "# N: nb states\n",
    "# K: nb observations\n",
    "\n",
    "def learnHMM(allx, allq, N, K, initTo1=True):\n",
    "    if initTo1:\n",
    "        eps = 1e-3 # You can play with this regularization parameter \n",
    "        A = np.ones((N,N))*eps\n",
    "        B = np.ones((N,K))*eps\n",
    "        Pi = np.ones(N)*eps\n",
    "    else:\n",
    "        A = np.zeros((N,N))\n",
    "        B = np.zeros((N,K))\n",
    "        Pi = np.zeros(N)\n",
    "    for x,q in zip(allx,allq):\n",
    "        Pi[int(q[0])] += 1\n",
    "        for i in range(len(q)-1):\n",
    "            A[int(q[i]),int(q[i+1])] += 1\n",
    "            B[int(q[i]),int(x[i])] += 1\n",
    "        B[int(q[-1]),int(x[-1])] += 1 # last transition\n",
    "    A = A/np.maximum(A.sum(1).reshape(N,1),1) # normalisation\n",
    "    B = B/np.maximum(B.sum(1).reshape(N,1),1) # normalisation\n",
    "    Pi = Pi/Pi.sum()\n",
    "    return Pi , A, B\n",
    "\n",
    "def viterbi(x,Pi,A,B):\n",
    "    T = len(x)\n",
    "    N = len(Pi)\n",
    "    logA = np.log(A)\n",
    "    logB = np.log(B)\n",
    "    logdelta = np.zeros((N,T))\n",
    "    psi = np.zeros((N,T), dtype=int)\n",
    "    S = np.zeros(T)\n",
    "    logdelta[:,0] = np.log(Pi) + logB[:,int(x[0])]\n",
    "    #forward\n",
    "    for t in range(1,T):\n",
    "        logdelta[:,t] = (logdelta[:,t-1].reshape(N,1) + logA).max(0) + logB[:,int(x[t])]\n",
    "        psi[:,t] = (logdelta[:,t-1].reshape(N,1) + logA).argmax(0)\n",
    "    # backward\n",
    "    logp = logdelta[:,-1].max()\n",
    "    S[T-1] = logdelta[:,-1].argmax()\n",
    "    for i in range(2,T+1):\n",
    "        S[int(T-i)] = psi[int(S[int(T-i+1)]),int(T-i+1)]\n",
    "    return S, logp #, delta, psi\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data encoding\n",
    "\n",
    "We will map each word to an index for traing the HMM (see code below):\n",
    "```\n",
    " The cat is in the garden => 1 2 3 4 1 5\n",
    "```\n",
    "We have to understand the dictionary functionning to retrieve the words corresponding to indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4570 42  in the dictionary\n"
     ]
    }
   ],
   "source": [
    "# alldocs etant issu du chargement des données\n",
    "# la mise en forme des données est fournie ici\n",
    "# afin de produire des analyses qualitative, vous devez malgré tout comprendre le fonctionnement des dictionnaires\n",
    "\n",
    "buf = [[m for m,pos in d ] for d in alldocs]\n",
    "mots = []\n",
    "[mots.extend(b) for b in buf]\n",
    "mots = np.unique(np.array(mots))\n",
    "nMots = len(mots)+1 # mot inconnu\n",
    "\n",
    "mots2ind = dict(zip(mots,range(len(mots))))\n",
    "mots2ind[\"UUUUUUUU\"] = len(mots)\n",
    "\n",
    "buf2 = [[pos for m,pos in d ] for d in alldocs]\n",
    "\n",
    "cles = []\n",
    "[cles.extend(b) for b in buf2]\n",
    "cles = np.unique(np.array(cles))\n",
    "cles2ind = dict(zip(cles,range(len(cles))))\n",
    "\n",
    "nCles = len(cles)\n",
    "\n",
    "print(nMots,nCles,\" in the dictionary\")\n",
    "\n",
    "# mise en forme des données\n",
    "allx  = [[mots2ind[m] for m,pos in d] for d in alldocs]\n",
    "allxT = [[mots2ind.setdefault(m,len(mots)) for m,pos in d] for d in alldocsT]\n",
    "\n",
    "allq  = [[cles2ind[pos] for m,pos in d] for d in alldocs]\n",
    "allqT = [[cles2ind.setdefault(pos,len(cles)) for m,pos in d] for d in alldocsT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1140, 814, 563, 11, 1294, 4393, 3855, 2854, 3992, 1362, 4242, 1452, 2395, 2855, 1990, 4529, 446, 525, 4299, 3595, 4148, 3368, 2499, 446, 11, 283, 2861, 20]\n",
      "[18, 18, 18, 22, 18, 17, 32, 23, 32, 9, 13, 17, 33, 24, 17, 12, 18, 18, 29, 31, 13, 20, 12, 18, 22, 8, 20, 5]\n"
     ]
    }
   ],
   "source": [
    "# First doc:\n",
    "print(allx[0])\n",
    "print(allq[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You turn: apply HMMs to those data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HMM training \n",
    "Pi,A,B = learnHMM(allx, allq,nCles,nMots, initTo1=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nb_similare(seq1,seq2):\n",
    "    if(len(seq1) != len(seq2)):\n",
    "        raise Exception(\"Taille incompatibles !!!!\")\n",
    "    return np.sum(np.where(seq1 == seq2,1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HMM decoding and performances evaluation\n",
    "def get_accuracy(allxT,allqT):\n",
    "    nb =0\n",
    "    seqs = []\n",
    "    exem = []\n",
    "    for i_doc in range(len(allxT)):\n",
    "        seq_pos = viterbi(allxT[i_doc],Pi,A,B)[0]\n",
    "        seqs.extend(seq_pos)\n",
    "        nb += get_nb_similare(seq_pos,allqT[i_doc])\n",
    "        if(get_nb_similare(seq_pos,allqT[i_doc]) == len(seq_pos)):\n",
    "            exem.append(seq_pos)\n",
    "    return np.array(seqs),exem,nb\n",
    "seqs,exem,nb = get_accuracy(allxT,allqT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f633699ee50>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f63335341f0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "mat1 = []\n",
    "for elem in allqT:\n",
    "    mat1.extend(elem)\n",
    "plt.imshow(confusion_matrix(seqs,mat1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['DT', 'NNS', 'VBP', 'DT', 'NN', 'VBD', 'CD', 'NN', 'IN', 'DT', 'JJ', 'NN', 'IN', 'DT', 'JJ', 'NN', 'CC', 'VBD', 'IN', 'CD', 'NN', 'IN', 'DT', 'NN', 'RB', '.'], ['IN', 'DT', 'NNP', 'NNP', 'IN', 'NNP', 'NNP', ',', 'NN', 'IN', 'JJ', 'NN', 'VBD', 'IN', '$', 'CD', 'DT', 'NN', ',', 'IN', 'CD', 'NNS', '.'], ['PRP$', 'NN', 'VBD', 'IN', '$', 'CD', ',', 'IN', '$', 'CD', ',', 'IN', 'JJ', 'JJ', 'NN', '.']]\n"
     ]
    }
   ],
   "source": [
    "pos_cles = np.unique(cles)\n",
    "pos_final = []\n",
    "for elem in exem: \n",
    "    l = []\n",
    "    for code_pos in elem:\n",
    "        l.append(pos_cles[int(code_pos)])\n",
    "    pos_final.append(l)\n",
    "print(pos_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check : 1564 in test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qualitative Analyis:\n",
    "\n",
    "- With imshow on the parameters (ou d'un argsort), show what are the probable transition between labels.\n",
    "- Visualize the confusion matrices to understand what is challenging in this task\n",
    "- Find out examples that are corrected by Viterbi decoding\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Conditional Random Fields (CRF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CRF are disciminative models** representing the conditional distribution $P( \\mathbf{y} | \\mathbf{x} , \\mathbf{w})$:\n",
    "\n",
    "$$ P( \\mathbf{y} | \\mathbf{x} , \\mathbf{w})  = \\frac{e^{\\mathbf{w}^T  \\psi(\\mathbf{x},\\mathbf{y}) } }{\\sum\\limits_{y' \\in \\mathcal{y}}e^{\\mathbf{w}^T  \\psi(\\mathbf{x},\\mathbf{y}') } } $$ \n",
    "        \n",
    "**In 'linear-chain' CRFs**, the feature functions include **unary terms $u_k$** ($\\sim$ $\\mathbf{B}$ matrix in HMMs) and **pairwise terms $p_k$** ($\\sim$ $\\mathbf{A}$ matrix in HMMs):\n",
    "\n",
    "$$ \\psi(\\mathbf{x},\\mathbf{y}) = \\sum\\limits_{t=1}^T \\sum_{k=1}^K F_k(y_{t-1}, y_t, \\mathbf{x})  =   \\sum\\limits_{t=1}^T \\sum_{k=1}^K \\left[ u_k(y_t, \\mathbf{x}) + p_k(y_{t-1}, y_t, \\mathbf{x}) \\right]$$\n",
    "\n",
    "[<img src=\"https://thome.isir.upmc.fr/classes/RITAL/crf-obs2.png\" width=\"800\" >](https://thome.isir.upmc.fr/classes/RITAL/crf-obs2.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can directly use resources from nltk: \n",
    "- [CRFTagger](https://tedboy.github.io/nlps/generated/generated/nltk.CRFTagger.html)\n",
    "- [PerceptronTagger](https://www.nltk.org/_modules/nltk/tag/perceptron.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install python-crfsuite\n",
    "from nltk.tag.crf import CRFTagger\n",
    "tagger = CRFTagger()\n",
    "tagger.train(alldocs, 'out/crf.model') # training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and evaluating the model, as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1720\n"
     ]
    }
   ],
   "source": [
    "# tagger.tag_sents([['dog','is','good'], ['Cat','eat','meat']])\n",
    "\n",
    "# extraire les mots UNIQUEMENT a partir de alldocsT\n",
    "buf = [[m for m,pos in d ] for d in alldocsT]\n",
    "mots = []\n",
    "[mots.append(b) for b in buf]\n",
    "\n",
    "buf2 = [[pos for m,pos in d ] for d in alldocsT]\n",
    "cles = []\n",
    "[cles.append(b) for b in buf2]\n",
    "\n",
    "final_pred = tagger.tag_sents(mots) \n",
    "\n",
    "buf2_1 = [[pos for m,pos in d ] for d in final_pred]\n",
    "cles_1 = []\n",
    "[cles_1.append(b) for b in buf2_1]\n",
    "\n",
    "nb = 0\n",
    "for i_cle in range(len(cles)):\n",
    "    nb += get_nb_similare(np.array(cles[i_cle]),np.array(cles_1[i_cle]))\n",
    "print(nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check: 1720 bonnes réponses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perceptron\n",
    "from nltk.tag.perceptron    import PerceptronTagger\n",
    "tagger = PerceptronTagger(load=False)\n",
    "tagger.train(alldocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1745\n"
     ]
    }
   ],
   "source": [
    "final_pred = tagger.tag_sents(mots) \n",
    "\n",
    "buf2_1 = [[pos for m,pos in d ] for d in final_pred]\n",
    "cles_1 = []\n",
    "[cles_1.append(b) for b in buf2_1]\n",
    "\n",
    "nb = 0\n",
    "for i_cle in range(len(cles)):\n",
    "    nb += get_nb_similare(np.array(cles[i_cle]),np.array(cles_1[i_cle]))\n",
    "print(nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check: 1737 bonnes réponses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Going further\n",
    "\n",
    "- We test the application for PoS, we can run similar experiments for chunking (see parsing indication, very simple to load data)\n",
    "- Run  experiement on the larger dataset. This dataset is still largely used in research. This work can thus be included in your resume :)\n",
    "- Work will be purshed with word embeddings (next practical), and for [NER](https://www.clips.uantwerpen.be/conll2003/ner/) with RNNs (X. Tannier)\n",
    "- [State-of-the-art resources](https://github.com/stanfordnlp/stanza/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
